{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a91ab0-392c-45eb-98b0-ec8644c25b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc740814-151e-4bbc-9bc6-d54e3659a290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class anomaly_detection_autoencoder:\n",
    "    def __init__(self, n_splits=4):\n",
    "        self.n_splits = n_splits\n",
    "        self.reconstructed_data_lst = []\n",
    "        self.residual_lst = []\n",
    "        self.mse_scores = []\n",
    "        self.fold_data = []\n",
    "\n",
    "    def fit(self, input_array):\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=False)\n",
    "        for fold_idx, (train_index, test_index) in enumerate(kf.split(input_array), start=1):\n",
    "            X_train, X_test = input_array[train_index], input_array[test_index]\n",
    "\n",
    "            # Save the data of each fold\n",
    "            self.fold_data.append({\n",
    "                'fold_idx': fold_idx,\n",
    "                'train': (train_index[0], train_index[-1]),\n",
    "                'test': (test_index[0], test_index[-1])\n",
    "            })\n",
    "\n",
    "            model = keras.Sequential([\n",
    "                keras.layers.Input(shape=(input_array.shape[1],)),  # dimension of the data\n",
    "                keras.layers.Dense(30, activation='relu'),  # typical adjustment range : 10~50\n",
    "                keras.layers.Dense(input_array.shape[1], activation='linear')  # output : reconstructed the input data\n",
    "            ])\n",
    "\n",
    "            # Setting up the learning process\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error')  # adam: gradient descent algorithm\n",
    "\n",
    "            # Model fitting\n",
    "            model.fit(X_train, X_train, epochs=30, batch_size=32)\n",
    "\n",
    "            # Model reconstruction\n",
    "            reconstructed_data = model.predict(X_test)\n",
    "            self.reconstructed_data_lst.append(reconstructed_data)\n",
    "\n",
    "            # Calculate the residual with raw and reconstructed time-series\n",
    "            residual = X_test - reconstructed_data\n",
    "            self.residual_lst.append(residual)\n",
    "\n",
    "            # Calculate and save the evaluation result \n",
    "            mse = mean_squared_error(X_test, reconstructed_data)\n",
    "            self.mse_scores.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e517f6-ed43-4c95-abfe-b6e82fc876ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_pearson_correlation_similarity(series1, series2):\n",
    "    correlation_coefficient, p_value = pearsonr(series1, series2)\n",
    "    return correlation_coefficient\n",
    "\n",
    "def calculate_smape_similarity(series1, series2):\n",
    "    return np.mean((np.abs(series1-series2))/(np.abs(series1)+np.abs(series2)))*100\n",
    "\n",
    "def calculate_cosine_similarity(series1, series2):\n",
    "    return 1 - cosine(series1, series2)\n",
    "\n",
    "def calculate_fastdtw_similarity(series1, series2):\n",
    "    distance, _ = fastdtw(series1, series2)\n",
    "    return distance\n",
    "\n",
    "def measure_similarity(df, anomaly_df):\n",
    "    \n",
    "    result = pd.DataFrame(index=df.columns)\n",
    "    \n",
    "    # # Zero Division prevent\n",
    "    # df.replace(0, 1e-10, inplace=True)\n",
    "    # anomaly_df.replace(0, 1e-10, inplace=True)\n",
    "    \n",
    "    for col in result.index:\n",
    "        \n",
    "        # Pearson\n",
    "        pearson = calculate_pearson_correlation_similarity(df[ref], df[col])\n",
    "        anomaly_pearson = calculate_pearson_correlation_similarity(anomaly_df[ref], anomaly_df[col])    \n",
    "        \n",
    "        # FastDTW\n",
    "        distance = calculate_fastdtw_similarity(df[ref], df[col])\n",
    "        anomaly_distance = calculate_fastdtw_similarity(anomaly_df[ref], anomaly_df[col])\n",
    "\n",
    "        # SMAPE\n",
    "        smape = calculate_smape_similarity(df[ref], df[col])\n",
    "        anomaly_smape = calculate_smape_similarity(anomaly_df[ref], anomaly_df[col])\n",
    "\n",
    "        # Cosine Similarity\n",
    "        cosine_similarity = calculate_cosine_similarity(df[ref], df[col])\n",
    "        anomaly_cosine_similarity = calculate_cosine_similarity(anomaly_df[ref], anomaly_df[col])\n",
    "        \n",
    "        result.at[col, 'pearson'] = pearson\n",
    "        result.at[col, 'pearson_anomaly'] = anomaly_pearson\n",
    "        \n",
    "        result.at[col, 'Cosine'] = cosine_similarity\n",
    "        result.at[col, 'Cosine_anomaly'] = anomaly_cosine_similarity\n",
    "\n",
    "        result.at[col, 'FastDTW'] = distance\n",
    "        result.at[col, 'FastDTW_anomaly'] = anomaly_distance \n",
    "\n",
    "        result.at[col, 'SMAPE'] = smape\n",
    "        result.at[col, 'SMAPE_anomaly'] = anomaly_smape\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f4d6c-3d91-46c0-809f-c313e813e556",
   "metadata": {},
   "source": [
    "## Data definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d83b22-37aa-4949-8307-49b3e47abac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define database\n",
    "stock = pd.read_csv('./data/stock.csv', index_col=0)\n",
    "stock.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d056a448-acb8-4a25-a747-7ff479f26a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select reference time-series\n",
    "ref = 'AAPL'\n",
    "df = stock[stock.Symbol == ref].iloc[:, :-1] # Except the 'Symbol' column (You should except the string columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999b01d-49d7-437f-a7dd-e216ffecac5f",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928f3c66-1f9c-42cb-96fe-2abd9391e481",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964ec8ba-b1a4-4183-87ba-3e7d747fad2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply sacling to reference data\n",
    "scaler = RobustScaler()\n",
    "df_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6059e3e-8510-43d8-89f1-fcf1c1921059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "pca = PCA()\n",
    "df_scaled_pca = pca.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "753fc8e3-2f14-40af-b396-eb3fd37adaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eigen_value</th>\n",
       "      <th>contribution_rate</th>\n",
       "      <th>cumulative_contribution_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pca1</th>\n",
       "      <td>1.866036</td>\n",
       "      <td>0.754444</td>\n",
       "      <td>0.754444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca2</th>\n",
       "      <td>0.606852</td>\n",
       "      <td>0.245352</td>\n",
       "      <td>0.999796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca3</th>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca4</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca5</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca6</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      eigen_value  contribution_rate  cumulative_contribution_rate\n",
       "pca1     1.866036           0.754444                      0.754444\n",
       "pca2     0.606852           0.245352                      0.999796\n",
       "pca3     0.000364           0.000147                      0.999943\n",
       "pca4     0.000092           0.000037                      0.999980\n",
       "pca5     0.000034           0.000014                      0.999994\n",
       "pca6     0.000015           0.000006                      1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the principal component contribution Rate\n",
    "pca_results = pd.DataFrame({'eigen_value': pca.explained_variance_,\n",
    "                            'contribution_rate': pca.explained_variance_ratio_,\n",
    "                            'cumulative_contribution_rate': pca.explained_variance_ratio_.cumsum(),})\n",
    "\n",
    "pca_results.index = ['pca' + str(i) for i in range(1, len(pca_results) + 1)]\n",
    "\n",
    "pca_contribute_lst = list(pca.explained_variance_ratio_) # Create contribution rate list\n",
    "pca_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ef17c-face-4c1a-ab27-7eb1c2b4e471",
   "metadata": {},
   "source": [
    "### Subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8737dda-7c16-492c-ac95-8a3964bc2dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply scaling and pca to time-series database\n",
    "stocks_scaled_pca_lst = []\n",
    "\n",
    "for category, group in stock.groupby('Symbol'):\n",
    "    group.drop('Symbol', axis=1, inplace=True) # Except the 'Symbol' column\n",
    "    group_scaled = RobustScaler().fit_transform(group)\n",
    "    group_scaled_pca = PCA().fit_transform(group_scaled)\n",
    "    group_scaled_pca_df = pd.DataFrame(group_scaled_pca, index=group.index)\n",
    "    group_scaled_pca_df['Symbol'] = category\n",
    "    \n",
    "    stocks_scaled_pca_lst.append(group_scaled_pca_df)\n",
    "\n",
    "stocks_scaled_pca = pd.concat(stocks_scaled_pca_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d314e237-cdd2-4ef5-a03a-e7c524f53481",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34541014-f529-48ac-a271-57b9c62443da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameter Setting\n",
    "\"\"\"\n",
    "pca_cnt = 2  # Number of principal components\n",
    "contamination = 0.05 # Anomaly contamination rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728c1b9-df84-454e-b35c-0fbe15c5add7",
   "metadata": {},
   "source": [
    "### [Option: 1] Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60afc02-e8f8-4386-b089-b29f058e147e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Fitting\n",
    "IF = IsolationForest(contamination=contamination).fit(df_scaled_pca)\n",
    "anomaly_index, = np.where(IF.predict(df_scaled_pca) == -1)\n",
    "anomaly_ts = df.index[anomaly_index] # # abnormal timestamp extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b79ad4-5cc0-4b92-a41e-2b8930d055b2",
   "metadata": {},
   "source": [
    "### [Option: 2] Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2c447-f5f0-4c30-8d16-bc8f735bc6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "AE = anomaly_detection_autoencoder(n_splits=4)\n",
    "AE.fit(df_scaled_pca)\n",
    "\n",
    "# Extract the time stamp of the outliers based on the residuals\n",
    "residual_df = pd.DataFrame(np.vstack(AE.residual_lst), index=df.index) \n",
    "residual_sum = np.sum(residual_df, axis=1).sort_values(ascending=False) # Sum of resuidual\n",
    "anomaly_ts = residual_sum.head(int(len(residual_sum) * contamination)).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3160e-3762-4836-9207-7b0df77c24fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Measuring similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41fc95e6-a45a-47b3-af63-c5dc66b534af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the subsequence time-series by anomaly timestamp\n",
    "stocks_df = stocks_scaled_pca.pivot(columns='Symbol') # Time-series with normal timestamp\n",
    "stocks_anomaly_df = stocks_df[stocks_df.index.isin(anomaly_ts)] # Time-series with abnormal timestamp\n",
    "\n",
    "stocks_df_lst = list(map(lambda x: stocks_df[x], range(0, pca_cnt)))\n",
    "stocks_df_anomaly_lst = list(map(lambda x: stocks_anomaly_df[x], range(0, pca_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b25e8ad-2554-496e-83de-96ff5ede19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure similarity to normal and abnormal\n",
    "result_lst = []\n",
    "for i in range(0, pca_cnt): \n",
    "    result_lst.append(measure_similarity(stocks_df_lst[i], stocks_df_anomaly_lst[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9645be-d1b8-41d0-a5d8-a34d6ba907df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply contribution rate to the similarity of each principal component\n",
    "result_weight_df = sum(map(lambda x: result_lst[x] * pca_contribute_lst[x], range(pca_cnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6606d-3f81-4655-9a2b-6ceaa276b20b",
   "metadata": {},
   "source": [
    "## Spearman's rank correlaiton coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d7fa5e5-a2f7-4c93-833e-c0b6edd665f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Rank Variable dataframe\n",
    "result_rank = pd.concat([result_weight_df.iloc[:, :4].rank(ascending=False, method='first'),\n",
    "                         result_weight_df.iloc[:,4:].rank(ascending=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e49efd6-2412-45c7-9a90-1f0c2f976e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rank by Spearman's rank correlation coefficient \n",
    "result_rank_spearman = result_rank.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf6e319-2d0a-41d3-abd9-f3bdce562896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearson</th>\n",
       "      <th>Cosine</th>\n",
       "      <th>FastDTW</th>\n",
       "      <th>SMAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pearson_anomaly</th>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.689265</td>\n",
       "      <td>0.744062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cosine_anomaly</th>\n",
       "      <td>0.750603</td>\n",
       "      <td>0.750603</td>\n",
       "      <td>0.769085</td>\n",
       "      <td>0.710471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FastDTW_anomaly</th>\n",
       "      <td>0.654029</td>\n",
       "      <td>0.654029</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>0.780102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAPE_anomaly</th>\n",
       "      <td>0.702298</td>\n",
       "      <td>0.702298</td>\n",
       "      <td>0.828443</td>\n",
       "      <td>0.822514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pearson    Cosine   FastDTW     SMAPE\n",
       "pearson_anomaly  0.816718  0.816718  0.689265  0.744062\n",
       "Cosine_anomaly   0.750603  0.750603  0.769085  0.710471\n",
       "FastDTW_anomaly  0.654029  0.654029  0.864866  0.780102\n",
       "SMAPE_anomaly    0.702298  0.702298  0.828443  0.822514"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check performance based on correlation coefficient with whole and subsequence time-series\n",
    "performance = result_rank_spearman.iloc[1::2, ::2]\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2aa35e5-aa65-466d-a7c1-beabfa10e9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "AAPL     1.0\n",
       "ABVC    99.0\n",
       "ACMR    41.0\n",
       "AMGN    12.0\n",
       "AMZN    10.0\n",
       "        ... \n",
       "VNOM    25.0\n",
       "XELA    96.0\n",
       "YI      77.0\n",
       "ZTEK    75.0\n",
       "ZVRA    82.0\n",
       "Name: FastDTW_anomaly, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommend the rank\n",
    "recommend_rank_name = performance.max().idxmax() + '_anomaly'\n",
    "recommend_rank = result_rank[recommend_rank_name]\n",
    "recommend_rank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
